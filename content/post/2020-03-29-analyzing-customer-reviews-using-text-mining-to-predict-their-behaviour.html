---
title: Analyzing Customer Reviews Using Text Mining to Predict Their Behaviour
author: Scott Miner
date: '2020-03-29'
slug: analyzing-customer-reviews-using-text-mining-to-predict-their-behaviour
categories:
  - Text-Mining
tags: []
---



<p>I found a text mining tutorial online at <a href="https://medium.com/analytics-vidhya/customer-review-analytics-using-text-mining-cd1e17d6ee4e" class="uri">https://medium.com/analytics-vidhya/customer-review-analytics-using-text-mining-cd1e17d6ee4e</a>.</p>
<p>The article is by Sowmya Vivek. The tutorial aims to analyze customer reviews to predict if customers will recommend products.</p>
<p>We obtain the data set from Kaggle. (<a href="https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews/home" class="uri">https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews/home</a>).</p>
<p>The data is from a Women’s Clothing E-Commerce site.</p>
<p>The dataset contains 23,486 rows and 10 feature variables.</p>
<p>Each row corresponds to a customer review and includes the following variables:</p>
<ul>
<li>Clothing ID: Integer Categorical variable that refers to the specific piece being reviewed.</li>
<li>Age: Positive Integer variable of the reviewers age.</li>
<li>Title: String variable for the title of the review.</li>
<li>Review Text: String variable for the review body.</li>
<li>Rating: Positive Ordinal Integer variable for the product score granted by the customer from 1 Worst, to 5 Best.</li>
<li>Recommended IND: Binary variable stating where the customer recommends the product. 1 is recommended, 0 is not recommended.</li>
<li>Positive Feedback Count: Positive Integer documenting the number of other customers who found this review positive.</li>
<li>Division Name: Categorical name of the product high level division.</li>
<li>Department Name: Categorical name of the product department name.</li>
<li>Class Name: Categorical name of the product class name.</li>
</ul>
<p>We will use the following techniques to understand various aspects of text mining:</p>
<ul>
<li><p><em>Exploratory analysis of text data</em> (Review Text) individually and based on how it impacts the customer decision to recommend the product (Recommended IND)</p></li>
<li><p><em>Classification models</em> built based on the review text as the independent variable to predict whether a customer recommends a product.</p></li>
</ul>
<p>Additionally, the focus is to understand text mining and to understand differences between customers who recommend a product and those who don’t rather than predicting the customer action based on the review. We are focusing more on variable importance and coefficient scores of the models than model performance measures.</p>
<p>We have 2 broad categories of text mining approaches:</p>
<ul>
<li><p><em>semantic parsing</em> where the word sequence, word usage, as noun or verb, hierarchical word structure etc matters.</p></li>
<li><p><em>Bag of words</em> where all the words are analysed as a single token and order does not matter.</p></li>
<li><p>Step 1: Text extraction &amp; creating a corpus</p></li>
<li><p>Step 2: Text pre-processing</p></li>
<li><p>Step 3: Creating the document term-matrix (DTM) &amp; term-document-matrix (TDM)</p></li>
<li><p>Step 4: Exploratory text analysis (word cloud, polarized plot and dendrograms</p></li>
<li><p>Step 5: Feature extraction by removing sparsity</p></li>
<li><p>Step 6: Classification models</p></li>
</ul>
<div id="step1---text-extraction-creating-a-corpus" class="section level1">
<h1>STEP1 - Text extraction &amp; creating a corpus</h1>
<div id="initial-setup" class="section level4">
<h4>Initial setup</h4>
<p>The packages required for mining are loaded in the R environment:</p>
<pre class="r"><code># install.packages(&quot;ggthemes&quot;)
# install.packages(qdap)
# install.packages(dplyr)
# install.packages(tm)
# install.packages(wordcloud)
# install.packages(plotrix)
# install.packages(dendextend)
# install.packages(ggplot2)
# install.packages(ggthemes)
# install.packages(RWeka)
# install.packages(reshape2)
# install.packages(quanteda)
library(qdap)
library(dplyr)
library(tm)
library(wordcloud)
library(plotrix)
library(dendextend)
library(ggplot2)
library(ggthemes)
library(RWeka)
library(reshape2)
library(quanteda)</code></pre>
<p>I had to go: here <a href="https://www.r-statistics.com/2012/08/how-to-load-the-rjava-package-after-the-error-java_home-cannot-be-determined-from-the-registry/" class="uri">https://www.r-statistics.com/2012/08/how-to-load-the-rjava-package-after-the-error-java_home-cannot-be-determined-from-the-registry/</a> to install the correct version of Java.</p>
<p>Additionally, I went to this website: <a href="https://www.java.com/en/download/manual.jsp" class="uri">https://www.java.com/en/download/manual.jsp</a></p>
<p>After that, I resolved the error “JAVA_HOME cannot be determined from the Registry” by installing a Java version.</p>
<p>After loading the required packages, we set the working directory and load in the csv files.</p>
<pre class="r"><code>review=read.csv(&quot;~/OneDrive/Documents/datasets/womens-ecommerce-clothing-reviews/Womens Clothing E-Commerce Reviews.csv&quot;, stringsAsFactors = FALSE)
names(review)</code></pre>
<pre><code>##  [1] &quot;X&quot;                       &quot;Clothing.ID&quot;            
##  [3] &quot;Age&quot;                     &quot;Title&quot;                  
##  [5] &quot;Review.Text&quot;             &quot;Rating&quot;                 
##  [7] &quot;Recommended.IND&quot;         &quot;Positive.Feedback.Count&quot;
##  [9] &quot;Division.Name&quot;           &quot;Department.Name&quot;        
## [11] &quot;Class.Name&quot;</code></pre>
<p><strong>Review.Text</strong> contains the customer reviews received for various products.</p>
<ol style="list-style-type: decimal">
<li>Review.text is converted into a collection of text documents or a <strong>“Corpus”</strong>.</li>
<li>To convert the text into a corpus, we use the “tm” package in R.</li>
<li>We pass a source object as a paramter to the Corpus method.</li>
<li>The source object is similar to an abstract input location. The source we use here is a “Vectorsource” which inputs only character vectors.</li>
<li>The Review.text column is now converted to a corpus that we call “corpus_review”</li>
</ol>
<pre class="r"><code>corpus_review=Corpus(VectorSource(review$Review.Text))</code></pre>
</div>
<div id="step2---text-pre-processing" class="section level2">
<h2>STEP2 - Text Pre-processing</h2>
<p>Common pre-processing steps:</p>
<ol style="list-style-type: decimal">
<li>Convert to lower case–this way, if there are 2 words “Dress” and “dress”, we will convert to a single entry “dress”</li>
</ol>
<pre class="r"><code>corpus_review=tm_map(corpus_review, tolower)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Remove Punctuation: <code>corpus_review=tm_map(corpus_review, removePunctuation)</code></li>
</ol>
<pre class="r"><code>corpus_review=tm_map(corpus_review, removePunctuation)</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Remove stopwords: If stopworse are not removed, they will appear in all the frequently used words list, and will not give the correct picture of the core words used in the text. <code>corpus_review=tm_map(corpus_review, removeWords, stopwords("english"))</code>
<ul>
<li>Also, remove custom stopwords, which are words specific to the dataset that may not add value to the text.</li>
</ul></li>
</ol>
<div id="stemming-a-document" class="section level3">
<h3>Stemming a document</h3>
<pre class="r"><code>corpus_review=suppressWarnings(tm_map(corpus_review, removeWords, stopwords(&quot;english&quot;)))
# remove custom stop words
corpus_review=suppressWarnings(tm_map(corpus_review, removeWords, c(&quot;also&quot;,&quot;get&quot;,&quot;like&quot;,&quot;company&quot;,&quot;made&quot;,&quot;can&quot;,&quot;im&quot;,&quot;dress&quot;,&quot;just&quot;,&quot;i&quot;)))</code></pre>
<p>Stemming is the process of reducing inflected (or derived) words to their word stem, base or root form-generally a written word form.</p>
<p><code>SnowballC</code> is used for document stemming. Complicated, complication, and complicate will reduce to complicat after stemming. This is to ensure that the same word is not repeated as multiple version is the DTM and TDM and only have the root of the word represented in the DTM and TDM.</p>
<pre class="r"><code>corpus_review=tm_map(corpus_review, stemDocument)

# view the corpus content
corpus_review[[8]][1]</code></pre>
<pre><code>## $content
## [1] &quot;order carbon store pick ton stuff alway tri use top pair skirt pant everyth went color realli nice charcoal shimmer went well pencil skirt flare pant etc compaint bit big sleev long doesnt go petit bit loos xxs kept wil ldecid later sinc light color alreadi sold hte smallest size&quot;</code></pre>
<p>The corpus object in R is a nested list, we can use the r syntax for lists to view contents of the corpus.</p>
<div id="frequently-used-words" class="section level4">
<h4>Frequently used words</h4>
<p>The text corpus is now cleaned and only contains the core words required for text mining. The next step is exploratory analysis. We first need to identify the most frequently used words.</p>
<pre class="r"><code>term_count &lt;- freq_terms(corpus_review, 20)

# plot 20 most frequent terms
plot(term_count)</code></pre>
<p><img src="/post/2020-03-29-analyzing-customer-reviews-using-text-mining-to-predict-their-behaviour_files/figure-html/most-frequent-terms-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="step3---create-the-ctm-tdm-from-the-corpus" class="section level4">
<h4>STEP3 - Create the CTM &amp; TDM from the corpus</h4>
<p>The pre-processed and cleaned up corpus is converted into a matrix called the document term matrix.</p>
<p>In a document-term matrix, rows correspond to documents in the collection and columns correspond to terms.</p>
<p>An easy way to start analyzing the information is to change the DTM/TDM into a simple matrix using <code>as.matrix()</code>.</p>
<pre class="r"><code>review_dtm &lt;- DocumentTermMatrix(corpus_review)
review_tdm &lt;- TermDocumentMatrix(corpus_review)</code></pre>
</div>
<div id="using-the-tdm-to-identify-frequent-terms" class="section level4">
<h4>Using the TDM to identify frequent terms</h4>
<pre class="r"><code># Convert TDM to matrix
review_m &lt;- as.matrix(review_tdm)
# Sum rows and frequency data frame
review_term_freq &lt;- rowSums(review_m)
# Sort term_frequency in descending order
review_term_freq &lt;- sort(review_term_freq, decreasing = T)
# View the top 10 most common words
review_term_freq[1:10]</code></pre>
<pre><code>##    love     fit    size    look     top    wear   color   great perfect   order 
##   11351   11310   10597    9276    8261    8047    7191    6084    5224    4983</code></pre>
</div>
<div id="exploratory-text-analysis" class="section level4">
<h4>Exploratory text analysis</h4>
<pre class="r"><code># plot a barchart of the 20 most common words
barplot(review_term_freq[1:20], col = &quot;steel blue&quot;, las = 2)</code></pre>
<p><img src="/post/2020-03-29-analyzing-customer-reviews-using-text-mining-to-predict-their-behaviour_files/figure-html/Plot-a-barchart-of-the-20-most-common-words-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="word-clouds" class="section level4">
<h4>Word clouds</h4>
<p>Word clouds vary the size of the words, based on the frequency.</p>
<pre class="r"><code>review_word_freq &lt;- data.frame(term = names(review_term_freq),
                               num = review_term_freq)

# Create a wordcloud for the values in word_freqs
suppressWarnings(wordcloud(review_word_freq$term, review_word_freq$num,
          max.words = 50, colors = &quot;red&quot;))</code></pre>
<p><img src="/post/2020-03-29-analyzing-customer-reviews-using-text-mining-to-predict-their-behaviour_files/figure-html/word-clouds-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>The word cloud can also receive a set of colors or a color palette as input to distinguish betweehn the more and the lesser frequent words in the cloud.</p>
<pre class="r"><code># Print the word cloud with the specified colors
suppressWarnings(wordcloud(review_word_freq$term, review_word_freq$num,
          max.words = 50, colors = c(&quot;aquamarine&quot;,&quot;darkgoldenrod&quot;,&quot;tomato&quot;)))</code></pre>
<p><img src="/post/2020-03-29-analyzing-customer-reviews-using-text-mining-to-predict-their-behaviour_files/figure-html/word-cloud-with-specified-colors-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="comparison-of-corpus" class="section level4">
<h4>Comparison of corpus</h4>
<p>Analyze the difference in keywords between those who recommend and those who don’t recommend the product.</p>
<p>We create 2 corpora – one for Recommend-yes and another for Recommend-no.</p>
<p>We repeat all the pre-processing steps done previously for both corpora.</p>
<p>Next, the frequenly used words are plotted as separate bar plots and word clouds for each of the corpora to understand the difference in the words used by customers who recommend a product vs those who don’t.</p>
</div>
<div id="word-clouds-for-comparison" class="section level4">
<h4>Word clouds for comparison</h4>
<p>Another way to compare word sets is to combine the corpora for yes and no and create comparison clouds which display both the sets of words in the same cloud.</p>
<p>We use 2 more versions of the word cloud – the <strong>commonality cloud</strong> and the <strong>comaprison cloud</strong>.</p>
<p>The commonality combines words and plots a word cloud</p>
<pre class="r"><code>all_yes &lt;- review %&gt;%
    filter(Recommended.IND == 1) %&gt;%
    select(Review.Text) %&gt;%
    paste(collapse = &quot;&quot;)

all_no &lt;- review %&gt;%
    filter(Recommended.IND == 0) %&gt;%
    select(Review.Text) %&gt;%
    paste(collapse = &quot;&quot;)

all_combine &lt;- c(all_yes, all_no)


corpus_review_all=Corpus(VectorSource(all_combine))

## Pre-processing - all
# Convert to lower-case
corpus_review_all=tm_map(corpus_review_all, tolower)

# Remove punctuation
corpus_review_all = suppressWarnings(tm_map(corpus_review_all, removePunctuation))

# Remove stopwords
corpus_review_all=suppressWarnings(tm_map(corpus_review_all, removeWords, stopwords(&quot;english&quot;)))
corpus_review_all=suppressWarnings(tm_map(corpus_review_all, removeWords, c(&quot;also&quot;,&quot;get&quot;,
                                                           &quot;like&quot;,&quot;company&quot;,&quot;made&quot;,&quot;can&quot;,&quot;im&quot;,
                                                           &quot;dress&quot;,&quot;just&quot;,&quot;i&quot;)))

# Stem document

corpus_review_all=suppressWarnings(tm_map(corpus_review_all, stemDocument))
review_tdm_all &lt;- TermDocumentMatrix(corpus_review_all)
all_m=as.matrix(review_tdm_all)
colnames(all_m)=c(&quot;Yes&quot;,&quot;No&quot;)

# Sum rows and frequency data frame
review_term_freq_all &lt;- rowSums(all_m)
review_word_freq_all &lt;- data.frame(term=names(review_term_freq_all),
                                   num = review_term_freq_all)

# Make commonality cloud
suppressWarnings(commonality.cloud(all_m,
                  colors = &quot;steelblue1&quot;,
                  max.words = 50))</code></pre>
<p><img src="/post/2020-03-29-analyzing-customer-reviews-using-text-mining-to-predict-their-behaviour_files/figure-html/combine-both-corpora-1.png" width="70%" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Create the comparison cloud
suppressWarnings(comparison.cloud(all_m,
                 colors = c(&quot;green&quot;, &quot;red&quot;),
                 max.words = 50))</code></pre>
<p><img src="/post/2020-03-29-analyzing-customer-reviews-using-text-mining-to-predict-their-behaviour_files/figure-html/comparison-cloud-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="polarized-tag-plot" class="section level4">
<h4>Polarized tag plot</h4>
<p>A polarized tag plot is an improved version of the commonality cloud. It determines the frequency of a term used in both the corpora under comparison.</p>
<p>The matrix is created with all the common words using a subset to ensure that it contains only words occurring in both the classes. The matrix has another column for the absolute difference between both the corpora for each word and the plot is made.</p>
<pre class="r"><code># Identify terms shared by both documents
common_words &lt;- subset(all_m, all_m[,1] &gt; 0 &amp; all_m[, 2] &gt; 0)

# calculate common words and difference
difference &lt;- abs(common_words[, 1] - common_words[, 2])
common_words &lt;- cbind(common_words, difference)
common_words &lt;- common_words[order(common_words[, 3],
                                   decreasing = T), ]
head(common_words)</code></pre>
<pre><code>##        Yes   No difference
## love  9831 1466       8365
## fit   9568 1664       7904
## size  8983 1565       7418
## wear  7015 1022       5993
## color 6097 1042       5055
## great 5527  530       4997</code></pre>
<pre class="r"><code>top25_df &lt;- data.frame(x = common_words[1:25, 1],
                       y = common_words[1:25, 2],
                       labels = rownames(common_words[1:25, ]))

# Make pyramid plot
pyramid.plot(top25_df$x, top25_df$y,
             labels = top25_df$labels,
             main = &quot;Words in Common&quot;, 
             gap = 2000,
             laxlab = NULL,
             raxlab =  NULL,
             unit = NULL,
             top.labels = c(&quot;Yes&quot;,
                            &quot;Words&quot;,
                            &quot;No&quot;)
)</code></pre>
<p><img src="/post/2020-03-29-analyzing-customer-reviews-using-text-mining-to-predict-their-behaviour_files/figure-html/continue-1.png" width="70%" style="display: block; margin: auto;" /></p>
<pre><code>## [1] 5.1 4.1 4.1 2.1</code></pre>
</div>
<div id="simple-word-clustering" class="section level4">
<h4>Simple word clustering</h4>
<p>Word clustering is used to identify word groups used together. Words clusters are visualized with dendrograms.</p>
<pre class="r"><code>review_tdm2 &lt;- removeSparseTerms(review_tdm, sparse = 0.9)
hc &lt;- hclust(d = dist(review_tdm2, method = &quot;euclidean&quot;), method = &quot;complete&quot;)

# Plot a dendrogram
plot(hc)</code></pre>
<p><img src="/post/2020-03-29-analyzing-customer-reviews-using-text-mining-to-predict-their-behaviour_files/figure-html/plot-a-dendrogram-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Soft, material and comfort have been used together.</p>
</div>
</div>
<div id="word-associations" class="section level3">
<h3>Word Associations</h3>
<p>We will demonstrate correlation between various words and the word “fit”.</p>
<pre class="r"><code># Create associations
associations &lt;- findAssocs(review_tdm, &quot;fit&quot;, 0.05)

# Create associations_df
associations_df &lt;- list_vect2df(associations)[, 2:3]

# Plot the associations_df values
ggplot(associations_df, aes(y = associations_df[,1])) +
  geom_point(aes(x = associations_df[, 2]),
             data = associations_df, size = 3) +
  ggtitle(&quot;Word Associations to &#39;fit&#39;&quot;) +
  theme_gdocs()</code></pre>
<p><img src="/post/2020-03-29-analyzing-customer-reviews-using-text-mining-to-predict-their-behaviour_files/figure-html/word-associations-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>The word “fit” has the greatest association with “perfect” and “size”, which is the positive aspect of the product. The third highest word associated with “fit” is “loos” which indicates the negative aspect of the product.</p>
<pre class="r"><code>## Create bi-grams
review_bigram &lt;- tokens(review$Review.Text) %&gt;%
  tokens_remove(&quot;\\p{P}&quot;, valuetype = &quot;regex&quot;, padding = TRUE) %&gt;%
  tokens_remove(stopwords(&quot;english&quot;), padding = TRUE) %&gt;%
  tokens_ngrams(n = 2) %&gt;%
  dfm()
topfeatures(review_bigram)</code></pre>
<pre><code>##     usually_wear      looks_great    fit_perfectly        well_made 
##              674              614              508              507 
##       usual_size         can_wear   fits_perfectly       size_small 
##              472              450              426              418 
##        look_like many_compliments 
##              375              365</code></pre>
</div>
</div>
<div id="create-tri-grams" class="section level2">
<h2>Create tri-grams</h2>
<pre class="r"><code>## Create tri-gramms
review_trigram &lt;- tokens(review$Review.Text) %&gt;%
  tokens_remove(&quot;\\p{P}&quot;, valuetype = &quot;regex&quot;, padding = TRUE) %&gt;%
  tokens_ngrams(n = 3) %&gt;%
  dfm()
topfeatures(review_trigram)</code></pre>
<pre><code>##      i_love_the   the_fabric_is    true_to_size       this_is_a   this_dress_is 
##            1491            1289            1284            1158            1112 
##     i_love_this         it_is_a the_material_is    in_the_store    on_the_model 
##            1022            1015             884             728             717</code></pre>
</div>
</div>
